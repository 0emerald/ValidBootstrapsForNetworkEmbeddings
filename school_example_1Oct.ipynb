{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 16:00:00.114548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-01 16:00:00.360086: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-01 16:00:00.393622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-01 16:00:00.393643: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-01 16:00:01.251886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-01 16:00:01.252141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-01 16:00:01.252150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "import os.path as osp\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import umap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from embedding_functions import *\n",
    "from experiment_setup import *\n",
    "from functions_for_bootstrap import *\n",
    "import numba as nb\n",
    "from scipy.stats import wasserstein_distance\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.integrate import simps\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.linalg import LinAlgError\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import LedoitWolf  # Import Ledoit-Wolf estimator\n",
    "from sklearn.covariance import shrunk_covariance, EmpiricalCovariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time windows: 18\n",
      "Number of nodes: 242\n"
     ]
    }
   ],
   "source": [
    "window = 60 * 60\n",
    "\n",
    "day_1_start = (8 * 60 + 30) * 60\n",
    "day_1_end = (17 * 60 + 30) * 60\n",
    "day_2_start = ((24 + 8) * 60 + 30) * 60\n",
    "day_2_end = ((24 + 17) * 60 + 30) * 60\n",
    "\n",
    "T1 = int((day_1_end - day_1_start) // window)\n",
    "T2 = int((day_2_end - day_2_start) // window)\n",
    "T = T1 + T2\n",
    "\n",
    "print(f\"Number of time windows: {T}\")\n",
    "\n",
    "# %%\n",
    "fname = \"ia-primary-school-proximity-attr.edges\"\n",
    "file = open(fname)\n",
    "\n",
    "label_dict = {\n",
    "    \"1A\": 0,\n",
    "    \"1B\": 1,\n",
    "    \"2A\": 2,\n",
    "    \"2B\": 3,\n",
    "    \"3A\": 4,\n",
    "    \"3B\": 5,\n",
    "    \"4A\": 6,\n",
    "    \"4B\": 7,\n",
    "    \"5A\": 8,\n",
    "    \"5B\": 9,\n",
    "    \"Teachers\": 10,\n",
    "}\n",
    "num_classes = 10\n",
    "\n",
    "nodes = []\n",
    "node_labels = []\n",
    "edge_tuples = []\n",
    "\n",
    "for line in file:\n",
    "    node_i, node_j, time, id_i, id_j = line.strip(\"\\n\").split(\",\")\n",
    "\n",
    "    if day_1_start <= int(time) < day_1_end:\n",
    "        t = (int(time) - day_1_start) // window\n",
    "    elif day_2_start <= int(time) < day_2_end:\n",
    "        t = T1 + (int(time) - day_2_start) // window\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if node_i not in nodes:\n",
    "        nodes.append(node_i)\n",
    "        node_labels.append(label_dict[id_i])\n",
    "\n",
    "    if node_j not in nodes:\n",
    "        nodes.append(node_j)\n",
    "        node_labels.append(label_dict[id_j])\n",
    "\n",
    "    edge_tuples.append([t, node_i, node_j])\n",
    "\n",
    "edge_tuples = np.unique(edge_tuples, axis=0)\n",
    "nodes = np.array(nodes)\n",
    "\n",
    "n = len(nodes)\n",
    "print(f\"Number of nodes: {n}\")\n",
    "\n",
    "node_dict = dict(zip(nodes[np.argsort(node_labels)], range(n)))\n",
    "node_labels = np.sort(node_labels)\n",
    "\n",
    "# %% [markdown]\n",
    "# Create a list of adjacency matrices.\n",
    "\n",
    "# %%\n",
    "As = np.zeros((T, n, n))\n",
    "\n",
    "for m in range(len(edge_tuples)):\n",
    "    t, i, j = edge_tuples[m]\n",
    "    As[int(t), node_dict[i], node_dict[j]] = 1\n",
    "    As[int(t), node_dict[j], node_dict[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data to work with existing code\n",
    "labels = node_labels\n",
    "\n",
    "# just look at first (whatever is specified) timepoint\n",
    "dense_adj = As[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area_above_below_curve(x, y):\n",
    "    area_above = 0.0\n",
    "    area_below = 0.0\n",
    "    \n",
    "    for i in range(1, len(x)):\n",
    "        x0, x1 = x[i - 1], x[i]\n",
    "        y0, y1 = y[i - 1], y[i]\n",
    "        line0, line1 = x0, x1  # Since line y = x\n",
    "        \n",
    "        if y1 == y0:  # Vertical segment\n",
    "            if y0 > x0:\n",
    "                area_above += (y0 - x0) * (x1 - x0)\n",
    "            else:\n",
    "                area_below += (x0 - y0) * (x1 - x0)\n",
    "            continue\n",
    "        \n",
    "        # Find intersection with y = x\n",
    "        if (y0 >= x0 and y1 >= x1) or (y0 <= x0 and y1 <= x1):\n",
    "            if y0 >= x0 and y1 >= x1:\n",
    "                area_above += 0.5 * (y0 + y1 - x0 - x1) * (x1 - x0)\n",
    "            else:\n",
    "                area_below += 0.5 * (x0 + x1 - y0 - y1) * (x1 - x0)\n",
    "        else:\n",
    "            x_intersect = x0 + (x0 - y0) * (x1 - x0) / (y1 - y0)\n",
    "            if y0 < x0:\n",
    "                area_below += 0.5 * (x0 - y0) * (x_intersect - x0)\n",
    "                area_above += 0.5 * (y1 - x1) * (x1 - x_intersect)\n",
    "            else:\n",
    "                area_above += 0.5 * (y0 - x0) * (x_intersect - x0)\n",
    "                area_below += 0.5 * (x1 - y1) * (x1 - x_intersect)\n",
    "    \n",
    "    return area_above, area_below\n",
    "\n",
    "\n",
    "def plot_ellipse(ax, mean, cov, color):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    order = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[order]\n",
    "    eigenvectors = eigenvectors[:, order]\n",
    "    angle = np.degrees(np.arctan2(*eigenvectors[:, 0][::-1]))\n",
    "    width, height = 2 * np.sqrt(eigenvalues[:2])\n",
    "    ellipse = Ellipse(mean, width, height, angle, edgecolor=color, facecolor='none', lw=2, label=f'Covariance Ellipse ({color})')\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "# TO AVOID SINGULAR MATRIX ERROR\n",
    "def points_within_ellipse(points, mean, cov, regularization=1e-32, threshold=3):\n",
    "    try:\n",
    "        # Attempt to calculate the inverse of the covariance matrix\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "    except LinAlgError:\n",
    "        # If the matrix is singular, regularize and retry\n",
    "        cov += np.eye(cov.shape[0]) * regularization\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "    \n",
    "    # Calculate the Mahalanobis distance from the mean\n",
    "    diff = points - mean\n",
    "    mahalanobis_distances = np.sum(diff @ inv_cov * diff, axis=1)\n",
    "    \n",
    "    # Points within the ellipse have a Mahalanobis distance <= threshold\n",
    "    return mahalanobis_distances <= threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

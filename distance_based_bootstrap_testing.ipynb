{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from embedding_functions import *\n",
    "from experiment_setup import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TO DO\n",
    "1. Embed two time points where a change may or may not occur\n",
    "2. Bootstrap the first graph B times and unfold embed to get bootstrapped embeddings\n",
    "3. Compute sigma hat as the sample variance of the bootstrapped embeddings for node i\n",
    "4. Check if the distance between the two embeddings is greater than 2 sigma hat (get p-value)\n",
    "\n",
    "REALITY CHECKS\n",
    "1. Check that you get uniform p-values when no change is present after many runs of the procedure on \n",
    "    iid data\n",
    "2. Make sure that it works on systems beyond SBM\n",
    "\n",
    "SUMMARY OF STUFF I'VE DONE\n",
    "- Got to the point where we can look at p-values to see if the embedding at the next time point has \n",
    "    changed significantly from the previous one relative to bootstrapped embeddings\n",
    "- For easier problems (iid_prob=0.85, closer to 1 = easier), p-values are uniformly distributed (with  \n",
    "    a high enough B).\n",
    "- P-values are non-uniform when a change occurs (great!)\n",
    "\n",
    "- However, in iid examples where the communities are closer (and therefore more difficult to bootstrap),\n",
    "    the p-values appear slightly super-uniform. So this procedure is not generally valid.\n",
    "- May need to look at some theory to make it generally valid.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an SBM of two communities\n",
    "n = 500\n",
    "T = 2\n",
    "d = 2\n",
    "As, tau, _ = make_iid(n, T, iid_prob=0.65)\n",
    "# As, tau, _ = make_temporal_simple(n, T, move_prob=0.9)\n",
    "\n",
    "# ya = UASE(As, d, flat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap first time point B times using parametric bootstrap\n",
    "B = 200\n",
    "X_hat = single_spectral(As[0], d)\n",
    "P_hat = X_hat @ X_hat.T\n",
    "A_star = [make_inhomogeneous_rg(P_hat) for _ in range(B)]\n",
    "\n",
    "A_star_with_obs = np.array(list(As) + A_star)\n",
    "\n",
    "ya_star_with_obs = UASE(A_star_with_obs, d, flat=False)\n",
    "ya_star = ya_star_with_obs[2:].copy()\n",
    "ya = ya_star_with_obs[:2].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate sigma hat for each node\n",
    "sigma_hats = np.zeros((n, d, d))\n",
    "for i in range(n):\n",
    "    sigma_hats[i] = np.cov(ya_star[:, i, :].T)\n",
    "\n",
    "\n",
    "# # %%\n",
    "# # Plot the differences to make sure that they look sensible\n",
    "# i = 0\n",
    "# new_point = ya[0, i, :] - ya[1, i, :]\n",
    "\n",
    "# bootstrap_points = np.zeros((B, d))\n",
    "# for b in range(B):\n",
    "#     bootstrap_points[b] = ya[0, i, :] - ya_star[b, i, :]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(bootstrap_points[:, 0], bootstrap_points[:, 1], color=\"C0\")\n",
    "# plt.scatter(new_point[0], new_point[1], color=\"red\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis test to check whether the observed difference is significant with respect to the\n",
    "#  bootstrap samples\n",
    "\n",
    "p_hat_list = []\n",
    "community_of_interest = 0\n",
    "for i in np.where(tau == community_of_interest)[0]:\n",
    "    observed = np.linalg.norm(ya[0, i, :] - ya[1, i, :])\n",
    "\n",
    "    all_tests = []\n",
    "    all_tests.append(observed)\n",
    "    # for b in range(B):\n",
    "    #     all_tests.append(np.linalg.norm(ya[0, i, :] - ya_star[b, i, :]))\n",
    "\n",
    "    sigma_hat = sigma_hats[i]\n",
    "    for b in range(B):\n",
    "        # Draw a bunch of samples from a normal dist and use a hypothesis test to check if the\n",
    "        #  observed difference is significant\n",
    "        normal_sample = np.random.multivariate_normal(\n",
    "            np.zeros(d), d * (sigma_hat), size=1\n",
    "        ).flatten()\n",
    "        all_tests.append(np.linalg.norm(normal_sample))\n",
    "\n",
    "    # Are new_point and bootstrap_points from the same distribution?\n",
    "    p_hat = 1 / (B + 1) * np.sum(all_tests >= observed)\n",
    "    p_hat_list.append(p_hat)\n",
    "\n",
    "# Plot the ROC curve\n",
    "alphas_list = []\n",
    "roc = []\n",
    "alphas = []\n",
    "for alpha in np.linspace(0, 1, 100):\n",
    "    alphas.append(alpha)\n",
    "    num_below_alpha = sum(p_hat_list < alpha)\n",
    "    roc_point = num_below_alpha / len(p_hat_list)\n",
    "    roc.append(roc_point)\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 2), np.linspace(0, 1, 2), linestyle=\"--\", c=\"grey\")\n",
    "_ = plt.plot(alphas, roc)\n",
    "_ = plt.title(\"P-values for community {}\".format(community_of_interest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embedding of the first time point with one of its boostrapped versions\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(ya[0, tau == 0, 0], ya[0, tau == 0, 1], color=\"C0\")\n",
    "plt.scatter(ya[0, tau == 1, 0], ya[0, tau == 1, 1], color=\"C1\")\n",
    "\n",
    "plt.scatter(ya_star[2, tau == 0, 0], ya_star[2, tau == 0, 1], color=\"blue\", alpha=0.4)\n",
    "plt.scatter(ya_star[2, tau == 1, 0], ya_star[2, tau == 1, 1], color=\"red\", alpha=0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(ya_star[:, 0, 0], ya_star[:, 0, 1], color=\"black\")\n",
    "plt.scatter(ya[0, 0, 0], ya[0, 0, 1], color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to true\n",
    "As_true, tau, _ = make_iid(n, 100, iid_prob=0.9)\n",
    "\n",
    "B = 100\n",
    "X_hat = single_spectral(As_true[0], d)\n",
    "P_hat = X_hat @ X_hat.T\n",
    "As_star = [make_inhomogeneous_rg(P_hat) for _ in range(B)]\n",
    "\n",
    "As_both = np.array(list(As_true) + As_star)\n",
    "\n",
    "ya_both = UASE(As_both, d, flat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ya_both[0, i, 0], ya_both[0, i, 1], color=\"red\")\n",
    "plt.scatter(ya_both[1:100, i, 0], ya_both[1:100, i, 1], color=\"green\")\n",
    "plt.scatter(ya_both[100:, i, 0], ya_both[100:, i, 1], color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
